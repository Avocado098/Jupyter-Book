{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76cf5bc9-897f-47e3-88a6-d63dd32c68f2",
   "metadata": {},
   "source": [
    "Name: **Rachel Jasmine Canaman** <br>\n",
    "Section: **DS4A**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0779af-25f3-483c-bf87-b9774ba15b6f",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Laboratory Task 2</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70523c02-3670-414f-a82d-8d98bb0f73c8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"image1.png\" alt=\"A centered image\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1615d0-4f2e-4df4-9c0c-19c91f9d30c5",
   "metadata": {},
   "source": [
    "**Objective:**  \n",
    "Perform a single forward pass through a simple artificial neural network (ANN) and compute the error.\n",
    "\n",
    "We are given:\n",
    "\n",
    "- Input vector: \\( x = \\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix} \\), and target output \\( y = 1 \\)\n",
    "\n",
    "- Hidden unit weights: \\( W_{\\text{hidden}} = \\begin{bmatrix} 0.2 & -0.3 \\\\ 0.4 & 0.1 \\\\ -0.5 & 0.2 \\end{bmatrix} \\)\n",
    "\n",
    "- Output weights: \\( w_{21} = -0.3 \\), \\( w_{22} = -0.2 \\)\n",
    "\n",
    "- Biases: \\( \\theta = \\begin{bmatrix} -0.4 \\\\ 0.2 \\\\ 0.1 \\end{bmatrix} \\)\n",
    "\n",
    "- Activation function (ReLU): \\( f(z) = \\max(0, z) \\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f5202-d008-4b09-97e4-5a68ef707713",
   "metadata": {},
   "source": [
    "**Step 1: Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7cd8da-e4e4-46ea-a4e3-231e51a48459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee192a-39f2-4681-b1b0-4c8adb6bf2bf",
   "metadata": {},
   "source": [
    "**Step 2: Define Inputs, Weights, and Biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e920a91e-71cd-44ec-a3ce-c97d16733329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and target\n",
    "x = np.array([1, 0, 1])   # input vector\n",
    "y = 1                     # target output\n",
    "\n",
    "# Hidden layer weights (3x2)\n",
    "W_hidden = np.array([\n",
    "    [0.2, -0.3],\n",
    "    [0.4,  0.1],\n",
    "    [-0.5, 0.2]\n",
    "])\n",
    "\n",
    "# Biases\n",
    "theta1, theta2, theta3 = -0.4, 0.2, 0.1\n",
    "\n",
    "# Output weights\n",
    "w_out = np.array([-0.3, -0.2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311864a5-c3e9-4676-b4e8-33be033af2ad",
   "metadata": {},
   "source": [
    "**Step 3: Forward Pass – Hidden Layer**\n",
    "\n",
    "We compute:  \n",
    "$z_{\\text{hidden}} = xW_{\\text{hidden}} + \\theta$ <br>\n",
    "$h = f(z_{\\text{hidden}})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e362a951-1bc1-4c2f-adb7-7022ee53c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden pre-activations: [-0.7  0.1]\n",
      "Hidden activations (after ReLU): [0.  0.1]\n"
     ]
    }
   ],
   "source": [
    "# Hidden layer pre-activation\n",
    "z_hidden = x @ W_hidden + np.array([theta1, theta2])\n",
    "\n",
    "# Apply ReLU activation\n",
    "h = np.maximum(0, z_hidden)\n",
    "\n",
    "print(\"Hidden pre-activations:\", z_hidden)\n",
    "print(\"Hidden activations (after ReLU):\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231a357-89e8-4008-b727-5b4674b8028f",
   "metadata": {},
   "source": [
    "**Step 4: Forward Pass – Output Layer**\n",
    "\n",
    "We compute:  \n",
    "$z_{\\text{out}} = h \\cdot w_{\\text{out}} + \\theta_3$ <br>\n",
    "$\\hat{y} = f(z_{\\text{out}})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74a6b5f-69b1-400b-a18f-b3d6c2c24032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output pre-activation: 0.08\n",
      "Predicted output: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Output pre-activation\n",
    "z_out = h @ w_out + theta3\n",
    "\n",
    "# Apply ReLU (for output unit)\n",
    "y_hat = max(0, z_out)\n",
    "\n",
    "print(\"Output pre-activation:\", z_out)\n",
    "print(\"Predicted output:\", y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b4f23-7707-4071-912c-5b8849937277",
   "metadata": {},
   "source": [
    "**Step 5: Error Computation**\n",
    "\n",
    "We use Mean Squared Error (MSE with 1/2 factor): $E = \\frac{1}{2}(y - \\hat{y})^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80388e25-475b-483b-9d36-4ae2e763afa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.4232\n"
     ]
    }
   ],
   "source": [
    "# Error calculation\n",
    "error = 0.5 * (y - y_hat)**2\n",
    "print(\"Error:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e9074-53a6-495c-9c10-71d6f41981ad",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- The input vector \\([1, 0, 1]\\) was passed through the network.\n",
    "- Hidden activations were:\n",
    "  - $h_1 = 0$\n",
    "  - $h_2 = 0.1$\n",
    "- Output prediction was $\\hat{y} = 0.08$.\n",
    "- The error was computed as: $E = 0.4232$\n",
    "\n",
    "This simple forward pass demonstrates how weights, biases, and activation functions combine to produce an output. It also highlights why training (backpropagation) is essential to reduce error and improve predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}